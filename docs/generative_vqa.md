# Generative VQA Model

Vietnamese Visual Question Answering vá»›i kiáº¿n trÃºc Encoder-Decoder, sinh cÃ¢u tráº£ lá»i thá»±c táº¿ thay vÃ¬ phÃ¢n loáº¡i.

## ğŸ“‹ Tá»•ng quan

### So sÃ¡nh vá»›i Classification VQA

| Äáº·c Ä‘iá»ƒm | Classification VQA | Generative VQA |
|----------|-------------------|----------------|
| **Output** | Class ID (0-459) | Chuá»—i tokens |
| **Vocabulary** | Giá»›i háº¡n (min_freq) | KhÃ´ng giá»›i háº¡n (64K tokens) |
| **CÃ¢u tráº£ lá»i má»›i** | âŒ KhÃ´ng thá»ƒ | âœ… CÃ³ thá»ƒ |
| **Xá»­ lÃ½ OOV** | `<unk>` | Sinh tá»«ng token |
| **Äá»™ linh hoáº¡t** | Tháº¥p | Cao |
| **Training** | CrossEntropy (class) | LM Loss (tokens) |

### Kiáº¿n trÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              INPUT                      â”‚
â”‚   ğŸ–¼ï¸ Image + â“ Question                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         VISUAL ENCODER                  â”‚
â”‚    CLIP ViT â†’ Visual Features           â”‚
â”‚    [CLS] + patches â†’ (197, 768)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       QUESTION ENCODER                  â”‚
â”‚    PhoBERT â†’ Question Features          â”‚
â”‚    tokens â†’ (seq_len, 768)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      CROSS-MODAL FUSION                 â”‚
â”‚    V + Q â†’ Fused Features               â”‚
â”‚    Cross-Attention + FFN                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      TRANSFORMER DECODER                â”‚
â”‚    Auto-regressive generation           â”‚
â”‚    6 layers Ã— 8 heads                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            OUTPUT                       â”‚
â”‚    ğŸ“ Generated Answer (tokens)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Training

```bash
# Basic training
python -m src.core.generative_vqa_pipeline --mode train

# With custom parameters
python -m src.core.generative_vqa_pipeline \
    --mode train \
    --images-dir data/raw/images \
    --text-file data/raw/texts/evaluate_60k_data_balanced_preprocessed.csv \
    --batch-size 16 \
    --epochs 20 \
    --learning-rate 5e-5 \
    --freeze-visual \
    --freeze-text
```

### Evaluation

```bash
python -m src.core.generative_vqa_pipeline \
    --mode evaluate \
    --resume checkpoints/generative/best_generative_model.pt
```

### Demo

```bash
python -m src.core.generative_vqa_pipeline \
    --mode demo \
    --resume checkpoints/generative/best_generative_model.pt
```

## ğŸ“ File Structure

```
src/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ generative_vqa_pipeline.py    # Main CLI pipeline
â”‚   â””â”€â”€ generative_training_pipeline.py  # Training logic
â”œâ”€â”€ data/
â”‚   â””â”€â”€ generative_dataset.py         # Seq2Seq dataset
â””â”€â”€ modeling/
    â””â”€â”€ meta_arch/
        â””â”€â”€ generative_vqa_model.py   # Model architecture
```

## âš™ï¸ Configuration

### Model Config

```python
from src.modeling.meta_arch.generative_vqa_model import get_default_generative_vqa_config

config = get_default_generative_vqa_config(
    visual_backbone='openai/clip-vit-base-patch32',
    text_encoder='vinai/phobert-base',
    vocab_size=64001,  # PhoBERT vocab
    freeze_visual_encoder=True,  # Freeze CLIP ViT
    freeze_question_encoder=True,  # Freeze PhoBERT
    num_decoder_layers=6,
    num_attention_heads=8,
    hidden_size=768,
    max_answer_length=64
)
```

### Training Config

```python
from src.core.generative_training_pipeline import GenerativeTrainingConfig

training_config = GenerativeTrainingConfig(
    num_epochs=20,
    learning_rate=5e-5,
    weight_decay=0.01,
    warmup_ratio=0.1,
    use_amp=True,  # Mixed precision
    gradient_accumulation_steps=2,
    early_stopping=True,
    patience=5,
    metric_for_best='bleu'
)
```

## ğŸ“Š Metrics

Generative VQA sá»­ dá»¥ng cÃ¡c metric NLG:

| Metric | MÃ´ táº£ |
|--------|-------|
| **BLEU-4** | N-gram precision vá»›i brevity penalty |
| **METEOR** | F1 dá»±a trÃªn synonyms vÃ  stemming |
| **ROUGE-L** | Longest Common Subsequence |
| **CIDEr** | TF-IDF weighted n-gram similarity |
| **Exact Match** | Khá»›p chÃ­nh xÃ¡c sau normalize |
| **Perplexity** | exp(loss) - Ä‘á»™ "ngáº¡c nhiÃªn" |

## ğŸ”§ Programmatic Usage

### Create Model

```python
from src.modeling.meta_arch import (
    GenerativeVQAModel,
    get_default_generative_vqa_config,
    create_generative_vqa_model
)

# Get config
config = get_default_generative_vqa_config(
    vocab_size=64001,
    freeze_visual_encoder=True,
    freeze_question_encoder=True
)

# Create model
model = create_generative_vqa_model(config)
model.to('cuda')

# Count parameters
total = sum(p.numel() for p in model.parameters())
trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"Total: {total:,}, Trainable: {trainable:,}")
```

### Create Dataset

```python
from src.data.generative_dataset import (
    GenerativeVQADataset,
    generative_vqa_collate_fn
)
from torch.utils.data import DataLoader
from transformers import AutoTokenizer
import pandas as pd

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base')

# Load data
df = pd.read_csv('data/raw/texts/evaluate_60k_data_balanced_preprocessed.csv')

# Create dataset
dataset = GenerativeVQADataset(
    df=df,
    images_dir='data/raw/images',
    tokenizer=tokenizer,
    max_question_length=64,
    max_answer_length=32
)

# Create dataloader
loader = DataLoader(
    dataset,
    batch_size=16,
    collate_fn=generative_vqa_collate_fn,
    shuffle=True
)
```

### Training Loop

```python
from torch.optim import AdamW

optimizer = AdamW(
    [p for p in model.parameters() if p.requires_grad],
    lr=5e-5
)

model.train()
for batch in loader:
    batch = {k: v.to('cuda') if isinstance(v, torch.Tensor) else v 
             for k, v in batch.items()}
    
    outputs = model(
        pixel_values=batch['image'],
        input_ids=batch['input_ids'],
        attention_mask=batch['attention_mask'],
        decoder_input_ids=batch['decoder_input_ids'],
        decoder_attention_mask=batch['decoder_attention_mask'],
        labels=batch['labels']
    )
    
    loss = outputs.loss
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
```

### Generation

```python
model.eval()
with torch.no_grad():
    generated_ids = model.generate(
        pixel_values=image.unsqueeze(0).to('cuda'),
        input_ids=question_ids.unsqueeze(0).to('cuda'),
        attention_mask=question_mask.unsqueeze(0).to('cuda'),
        max_length=64,
        num_beams=4,  # Beam search
        do_sample=False
    )
    
    answer = tokenizer.decode(generated_ids[0], skip_special_tokens=True)
    print(f"Generated: {answer}")
```

## ğŸ“ˆ Training Tips

1. **Freeze Encoders**: Báº¯t Ä‘áº§u vá»›i frozen CLIP vÃ  PhoBERT Ä‘á»ƒ decoder há»c trÆ°á»›c
2. **Learning Rate**: DÃ¹ng 5e-5 vá»›i warmup 10%
3. **Batch Size**: 16-32 vá»›i gradient accumulation náº¿u GPU nhá»
4. **Mixed Precision**: LuÃ´n báº­t AMP Ä‘á»ƒ tiáº¿t kiá»‡m memory
5. **Early Stopping**: DÃ¹ng BLEU lÃ m metric
6. **Generation**: Beam search (num_beams=4) thÆ°á»ng tá»‘t hÆ¡n greedy

## ğŸ› Common Issues

### Out of Memory
```bash
# Giáº£m batch size
--batch-size 8 --gradient-accumulation 4
```

### Empty Generation
- Model cáº§n train lÃ¢u hÆ¡n
- TÄƒng temperature khi sampling
- Sá»­ dá»¥ng beam search

### Slow Training
- Freeze encoders
- Enable mixed precision (--use-amp)
- TÄƒng num_workers

## ğŸ“š References

- [CLIP: Learning Transferable Visual Models](https://arxiv.org/abs/2103.00020)
- [PhoBERT: Pre-trained Vietnamese Language Models](https://arxiv.org/abs/2003.00744)
- [VQA: Visual Question Answering](https://arxiv.org/abs/1505.00468)
